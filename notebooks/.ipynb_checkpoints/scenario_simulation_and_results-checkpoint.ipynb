{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training des ML-Algorithmus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['www.api.binance.com', 'google.com', 'pool.burstcoin.ml']\n"
     ]
    }
   ],
   "source": [
    "import pickle as cPickle\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from math import pi\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.random.seed(31415)\n",
    "\n",
    "with open('combined_malicious_and_normal.csv', 'r') as csvfile:\n",
    "    csvtext = csvfile.readlines()\n",
    "    \n",
    "datensatz = []\n",
    "for line in csvtext:\n",
    "    datensatz.append(tuple(line.strip().split(', '))[0])\n",
    "    \n",
    "print(datensatz[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ergebnisse wieder anfügen für jeden Eintrag der Liste\n",
    "## Zugehörigkeit speichern (maliziös|ok)\n",
    "### ok = 1, maliziös = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Der erste Eintrag der kombinierten Liste ist maliziös. Ab da an alternierend.\n",
    "#0 = malicious\n",
    "#1 = good\n",
    "\n",
    "y = []\n",
    "for i in range(len(datensatz)):\n",
    "    if(i%2 == 0):\n",
    "       y.append(\"malicious\")\n",
    "    else:\n",
    "        y.append(\"ok\")\n",
    "#print(y[:3])\n",
    "#print(X[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz aufteilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['www.api.binance.com', 'google.com', 'pool.burstcoin.ml', 'youtube.com', 'www.uupool.com', 'tmall.com', 'mollnia.com', 'baidu.com', 'wn-iad02.e-planning.net', 'qq.com', 'jicfbcczdh.com', 'sohu.com', 'srv-2014-07-18-00.config.parsely.com', 'facebook.com']\n",
      "642842\n",
      "500000\n",
      "['www.api.binance.com', 'google.com', 'pool.burstcoin.ml', 'youtube.com', 'www.uupool.com', 'tmall.com', 'mollnia.com', 'baidu.com', 'wn-iad02.e-planning.net', 'qq.com', 'jicfbcczdh.com', 'sohu.com', 'srv-2014-07-18-00.config.parsely.com', 'facebook.com']\n",
      "['malicious', 'ok', 'malicious', 'ok', 'malicious', 'ok', 'malicious', 'ok', 'malicious', 'ok', 'malicious', 'ok', 'malicious', 'ok']\n"
     ]
    }
   ],
   "source": [
    "def filter_numbers(data):\n",
    "    function_data = copy.copy(data)\n",
    "    function_data = [item.replace('0', '1') for item in function_data]\n",
    "    function_data = [item.replace('2', '1') for item in function_data]\n",
    "    function_data = [item.replace('3', '1') for item in function_data]\n",
    "    function_data = [item.replace('4', '1') for item in function_data]\n",
    "    function_data = [item.replace('5', '1') for item in function_data]\n",
    "    function_data = [item.replace('6', '1') for item in function_data]\n",
    "    function_data = [item.replace('7', '1') for item in function_data]\n",
    "    function_data = [item.replace('8', '1') for item in function_data]\n",
    "    function_data = [item.replace('9', '1') for item in function_data]\n",
    "    return function_data\n",
    "\n",
    "def reduce_dataset(dataset_x, dataset_y, count,start_number=0):\n",
    "    X_temp = copy.copy(dataset_x)\n",
    "    y_temp = copy.copy(dataset_y)\n",
    "    \n",
    "    last_number = count+start_number\n",
    "    if last_number > len(X_temp):\n",
    "        last_number = len(X_temp)\n",
    "    \n",
    "    X_temp_i = X_temp[start_number:last_number:1]\n",
    "    y_temp_i = y_temp[start_number:last_number:1]   \n",
    "    return X_temp_i,y_temp_i\n",
    "\n",
    "X = datensatz\n",
    "\n",
    "print(X[:14])\n",
    "print(str(len(X)))\n",
    "X, y = reduce_dataset(X, y, 500000,0)\n",
    "print(str(len(X)))\n",
    "\n",
    "print(X[:14])\n",
    "print(y[:14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL's vektorisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vectorize(n_gram_min, n_gram_max, data, amount_of_params, vectorizer = None):\n",
    "    #dafür sorgen dass der Ursprungsdatensatz nicht korrumpiert wird\n",
    "    data = copy.deepcopy(data)\n",
    "    \n",
    "    #Initialisieren und Dictionary anlegen\n",
    "    if vectorizer == None:\n",
    "        vectorizer = CountVectorizer(analyzer='word', token_pattern=r'[^\\s+]', max_features = amount_of_params, ngram_range=(n_gram_min, n_gram_max))\n",
    "        start_time_fit = time.time()\n",
    "        vectorizer.fit(data)\n",
    "        end_time_fit = time.time()\n",
    "        time_for_fit = end_time_fit - start_time_fit\n",
    "        #print(\"time_for_fit:\" + str(time_for_fit))\n",
    "    \n",
    "    #Dictionary anwenden und N-Gram Vektorisierng durchführen\n",
    "    start_time_transform = time.time()\n",
    "    data = vectorizer.transform(data)\n",
    "    end_time_transform = time.time()\n",
    "    time_for_transform = end_time_transform - start_time_transform\n",
    "    \n",
    "    \n",
    "    #print(\"time_for_transform:\" + str(time_for_transform))   \n",
    "    return data, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blacklist Überprüfungs-Logik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_is_malicious(blacklist, domain_name):\n",
    "    is_malicious = False\n",
    "    if (domain_name in blacklist):\n",
    "        is_malicious = True\n",
    "    else:\n",
    "        is_malicious = False\n",
    "    return is_malicious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bearbeitung der Szenarien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter des Random Forest festlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_min = 0\n",
    "n_gram_max = 4\n",
    "max_param_amount = 726\n",
    "test_size_percentage = .11\n",
    "tree_count = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Szenario 1: 30% bekannt, 70% unbekannt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ursprungsdatenmenge und Testdatenmenge aufteilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vollständige Datensatzanzahl: 500000\n"
     ]
    }
   ],
   "source": [
    "groesse_der_bekannten_menge = 0.3\n",
    "\n",
    "print(\"Vollständige Datensatzanzahl: \" + str(len(X)))\n",
    "Vollstaendige_Anzahl = len(X)\n",
    "bekannte_Anzahl = round(Vollstaendige_Anzahl*groesse_der_bekannten_menge)\n",
    "unbekannte_Anzahl = Vollstaendige_Anzahl - bekannte_Anzahl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zufallsverfahren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 125279\n",
      "TN: 125394\n",
      "FP: 124606\n",
      "FN: 124721\n",
      "Accuracy auf der gemischten Datenmenge: 0.501346\n"
     ]
    }
   ],
   "source": [
    "#Auf dem gemischten Datensatz evaluieren\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(X)):\n",
    "    predicted_is_malicious = random.choice([True, False])\n",
    "    real_is_malicious = y[i]\n",
    "    if real_is_malicious == \"malicious\":\n",
    "        real_is_malicious = True\n",
    "    else:\n",
    "        real_is_malicious = False\n",
    "    \n",
    "    if real_is_malicious == True:\n",
    "        if predicted_is_malicious == True:\n",
    "            TP += 1\n",
    "        elif predicted_is_malicious == False:\n",
    "            FN += 1\n",
    "    elif real_is_malicious == False:\n",
    "        if predicted_is_malicious == True:\n",
    "            FP += 1   \n",
    "        elif predicted_is_malicious == False:\n",
    "            TN += 1\n",
    " \n",
    "print(\"TP: \" + str(TP))\n",
    "print(\"TN: \" + str(TN))\n",
    "print(\"FP: \" + str(FP))\n",
    "print(\"FN: \" + str(FN))\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(\"Accuracy auf der gemischten Datenmenge: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Test durchführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl bekannter zu unbekannter Datensätze:\n",
      "150000\n",
      "350000\n",
      "time_to_fit:16.098351001739502\n",
      "---------\n",
      "Accuracy der Trainingsmenge innerhalb der bekannten Menge: 0.9906067415730337\n",
      "---------\n",
      "TN: 65553\n",
      "FN: 125\n",
      "TP: 66693\n",
      "FP: 1129\n",
      "---------\n",
      "Accuracy der Validationsmenge innerhalb der bekannten Menge: 0.8595151515151516\n",
      "Accuracy:0.8595151515151516\n",
      "---------\n",
      "TN: 6521\n",
      "FN: 521\n",
      "TP: 7661\n",
      "FP: 1797\n",
      "---------\n",
      "Accuracy auf der unbekannten Menge: 0.837922077922078\n",
      "time_to_prediction:0.6712961196899414\n",
      "Accuracy auf der vollständigen gemischten Menge: 0.879638\n",
      "Accuracy:0.879638\n",
      "---------\n",
      "TN: 209351\n",
      "FN: 19532\n",
      "TP: 230468\n",
      "FP: 40649\n",
      "---------\n",
      "Sicherheitstest..:\n",
      "google.de: ['ok']\n",
      "1111-c111-1b11-a11d.reporo.net: ['malicious']\n"
     ]
    }
   ],
   "source": [
    "X_rf_filtered_numbers = filter_numbers(X)\n",
    "Xbekannt, ybekannt = reduce_dataset(X_rf_filtered_numbers, y, bekannte_Anzahl,0)\n",
    "Xunbekannt, yunbekannt = reduce_dataset(X_rf_filtered_numbers, y, unbekannte_Anzahl,bekannte_Anzahl)\n",
    "print(\"Anzahl bekannter zu unbekannter Datensätze:\")\n",
    "print(str(len(Xbekannt)))\n",
    "print(str(len(Xunbekannt)))\n",
    "#Training nur innerhalb der Ursprungsdatenmenge mit der zuvor ermittelten Test-Size-Größe\n",
    "vectorized_Xbekannt, vectorizer = vectorize(n_gram_min, n_gram_max, Xbekannt, max_param_amount)\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_Xbekannt, ybekannt, test_size=test_size_percentage, random_state=0)\n",
    "classifier = RandomForestClassifier(n_estimators=tree_count, random_state=0,n_jobs=-1)\n",
    "start_time_fit = time.time()\n",
    "classifier.fit(X_train, y_train) \n",
    "end_time_fit = time.time()\n",
    "time_fit = end_time_fit - start_time_fit \n",
    "print(\"time_to_fit:\" + str(time_fit))\n",
    "print(\"---------\")\n",
    "\n",
    "y_pred = classifier.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy der Trainingsmenge innerhalb der bekannten Menge: \" + str(accuracy))\n",
    "CM = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "print(\"---------\")\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "print(\"TN: \" + str(TN))\n",
    "print(\"FN: \" + str(FN))\n",
    "print(\"TP: \" + str(TP))\n",
    "print(\"FP: \" + str(FP))\n",
    "\n",
    "print(\"---------\")\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy der Validationsmenge innerhalb der bekannten Menge: \" + str(accuracy))\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy:\" + str(accuracy))\n",
    "print(\"---------\")\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "print(\"TN: \" + str(TN))\n",
    "print(\"FN: \" + str(FN))\n",
    "print(\"TP: \" + str(TP))\n",
    "print(\"FP: \" + str(FP))\n",
    "\n",
    "print(\"---------\")\n",
    "\n",
    "#Unbekannte Menge bearbeiten..\n",
    "vectorized_Xunbekannt, vectorizer = vectorize(n_gram_min, n_gram_max, Xunbekannt, max_param_amount, vectorizer)\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_Xunbekannt, yunbekannt, test_size=test_size_percentage, random_state=0)\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy auf der unbekannten Menge: \" + str(accuracy))\n",
    "\n",
    "#Memory freigeben\n",
    "del vectorized_Xbekannt, vectorized_Xunbekannt, X_train, X_test, y_train, y_test, y_pred\n",
    "\n",
    "#Beides zusammen bearbeiten für das zu ermittelnde Ergebnis\n",
    "vectorized_Xmix, vectorizer = vectorize(n_gram_min, n_gram_max, X_rf_filtered_numbers, max_param_amount, vectorizer)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(vectorized_Xmix, y, test_size=test_size_percentage, random_state=0)\n",
    "start_time_predict = time.time()\n",
    "y_pred = classifier.predict(vectorized_Xmix)\n",
    "end_time_predict = time.time()\n",
    "time_predict = end_time_predict - start_time_predict \n",
    "print(\"time_to_prediction:\" + str(time_predict))\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"Accuracy auf der vollständigen gemischten Menge: \" + str(accuracy))\n",
    "CM = confusion_matrix(y, y_pred)\n",
    "print(\"Accuracy:\" + str(accuracy))\n",
    "print(\"---------\")\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "print(\"TN: \" + str(TN))\n",
    "print(\"FN: \" + str(FN))\n",
    "print(\"TP: \" + str(TP))\n",
    "print(\"FP: \" + str(FP))\n",
    "print(\"---------\")\n",
    "\n",
    "print(\"Sicherheitstest..:\")\n",
    "vectorized_google, vectorizer = vectorize(n_gram_min, n_gram_max, [\"google.de\"], max_param_amount, vectorizer)\n",
    "print(\"google.de: \" + str(classifier.predict(vectorized_google)))\n",
    "vectorized_1111, vectorizer = vectorize(n_gram_min, n_gram_max, [\"1111-c111-1b11-a11d.reporo.net\"], max_param_amount, vectorizer)\n",
    "print(\"1111-c111-1b11-a11d.reporo.net: \" + str(classifier.predict(vectorized_1111)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blacklist erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Trainingset:150000\n",
      "Length Testset:350000\n",
      "time_blacklist_creation:0.0352482795715332\n",
      "Length Trainingset:75000\n"
     ]
    }
   ],
   "source": [
    "#Blacklist erstellen. Jeder maliziöse Inhalt des Ursprungsdatensatzes wird zu einem Eintrag.\n",
    "dataset_candidates, dataset_candidates_y = reduce_dataset(X, y, bekannte_Anzahl,0)\n",
    "testset_x, testset_y = reduce_dataset(X, y, unbekannte_Anzahl,bekannte_Anzahl)\n",
    "\n",
    "#print(dataset_candidates[:10])\n",
    "#print(dataset_candidates_y[:10])\n",
    "print(\"Length Trainingset:\" + str(len(dataset_candidates)))\n",
    "print(\"Length Testset:\" + str(len(testset_x)))\n",
    "\n",
    "#Dict wird verwendet, um die spätere Blacklistverwendung zu beschleunigen\n",
    "start_time_blacklist_creation = time.time()\n",
    "blacklist = dict()\n",
    "for i in range(len(dataset_candidates_y)):\n",
    "    if dataset_candidates_y[i] == \"malicious\":\n",
    "        blacklist[dataset_candidates[i]] = 'malicious'\n",
    "\n",
    "end_time_blacklist_creation = time.time()\n",
    "time_blacklist_creation = end_time_blacklist_creation - start_time_blacklist_creation \n",
    "print(\"time_blacklist_creation:\" + str(time_blacklist_creation))\n",
    "\n",
    "print(\"Length Trainingset:\" + str(len(blacklist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blacklist Test durchführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 75000\n",
      "TN: 75000\n",
      "FP: 0\n",
      "FN: 0\n",
      "Accuracy auf der bekannten Datenmenge: 1.0\n",
      "TP: 0\n",
      "TN: 175000\n",
      "FP: 0\n",
      "FN: 175000\n",
      "Accuracy auf der unbekannten Datenmenge: 0.5\n",
      "time_blacklist_prediction:0.2731785774230957\n",
      "TP: 75000\n",
      "TN: 250000\n",
      "FP: 0\n",
      "FN: 175000\n",
      "Accuracy auf der gemischten Datenmenge: 0.65\n"
     ]
    }
   ],
   "source": [
    "#Auf bekannter Datenmenge evaluieren\n",
    "blacklist_accuracy_history = list()\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(dataset_candidates)):\n",
    "    domain_name = dataset_candidates[i]\n",
    "    predicted_is_malicious = domain_is_malicious(blacklist, domain_name)\n",
    "    real_is_malicious = dataset_candidates_y[i]\n",
    "    if real_is_malicious == \"malicious\":\n",
    "        real_is_malicious = True\n",
    "    else:\n",
    "        real_is_malicious = False\n",
    "    \n",
    "    \n",
    "    \n",
    "    if real_is_malicious == True:\n",
    "        if predicted_is_malicious == True:\n",
    "            TP += 1\n",
    "        elif predicted_is_malicious == False:\n",
    "            FN += 1\n",
    "    elif real_is_malicious == False:\n",
    "        if predicted_is_malicious == True:\n",
    "            FP += 1   \n",
    "            print(domain_name)\n",
    "        elif predicted_is_malicious == False:\n",
    "            TN += 1\n",
    "\n",
    "print(\"TP: \" + str(TP))\n",
    "print(\"TN: \" + str(TN))\n",
    "print(\"FP: \" + str(FP))\n",
    "print(\"FN: \" + str(FN))\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(\"Accuracy auf der bekannten Datenmenge: \" + str(accuracy))\n",
    "\n",
    "\n",
    "#Auf unbekannter Datenmenge evaluieren\n",
    "blacklist_accuracy_history = list()\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(testset_x)):\n",
    "    domain_name = testset_x[i]\n",
    "    predicted_is_malicious = domain_is_malicious(blacklist, domain_name)\n",
    "    real_is_malicious = testset_y[i]\n",
    "    if real_is_malicious == \"malicious\":\n",
    "        real_is_malicious = True\n",
    "    else:\n",
    "        real_is_malicious = False\n",
    "    \n",
    "    if real_is_malicious == True:\n",
    "        if predicted_is_malicious == True:\n",
    "            TP += 1\n",
    "        elif predicted_is_malicious == False:\n",
    "            FN += 1\n",
    "    elif real_is_malicious == False:\n",
    "        if predicted_is_malicious == True:\n",
    "            FP += 1   \n",
    "        elif predicted_is_malicious == False:\n",
    "            TN += 1\n",
    "\n",
    "print(\"TP: \" + str(TP))\n",
    "print(\"TN: \" + str(TN))\n",
    "print(\"FP: \" + str(FP))\n",
    "print(\"FN: \" + str(FN))\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(\"Accuracy auf der unbekannten Datenmenge: \" + str(accuracy))\n",
    "\n",
    "#Auf dem gemischten Datensatz evaluieren\n",
    "blacklist_accuracy_history = list()\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(X)):\n",
    "    domain_name = X[i]\n",
    "    predicted_is_malicious = domain_is_malicious(blacklist, domain_name)\n",
    "    real_is_malicious = y[i]\n",
    "    if real_is_malicious == \"malicious\":\n",
    "        real_is_malicious = True\n",
    "    else:\n",
    "        real_is_malicious = False\n",
    "    \n",
    "    if real_is_malicious == True:\n",
    "        if predicted_is_malicious == True:\n",
    "            TP += 1\n",
    "        elif predicted_is_malicious == False:\n",
    "            FN += 1\n",
    "    elif real_is_malicious == False:\n",
    "        if predicted_is_malicious == True:\n",
    "            FP += 1   \n",
    "        elif predicted_is_malicious == False:\n",
    "            TN += 1\n",
    "            \n",
    "#Time Test ohne Confusion-Matrix-Berechnung\n",
    "start_time_blacklist_prediction = time.time()\n",
    "blacklist_accuracy_history = list()\n",
    "\n",
    "for i in range(len(X)):\n",
    "    domain_name = X[i]\n",
    "    predicted_is_malicious = domain_is_malicious(blacklist, domain_name)\n",
    "    real_is_malicious = y[i]\n",
    "    if real_is_malicious == \"malicious\":\n",
    "        real_is_malicious = True\n",
    "    else:\n",
    "        real_is_malicious = False          \n",
    "end_time_blacklist_prediction = time.time()\n",
    "time_blacklist_prediction = end_time_blacklist_prediction - start_time_blacklist_prediction\n",
    "print(\"time_blacklist_prediction:\" + str(time_blacklist_prediction))    \n",
    "\n",
    "\n",
    "print(\"TP: \" + str(TP))\n",
    "print(\"TN: \" + str(TN))\n",
    "print(\"FP: \" + str(FP))\n",
    "print(\"FN: \" + str(FN))\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(\"Accuracy auf der gemischten Datenmenge: \" + str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
